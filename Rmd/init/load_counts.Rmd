Load data
---------

### Samples

```{r sample_overview, results='asis'}
# Samples included in this analysis
if (CONFIG$include_tables) {
    kable(CONFIG$samples, caption='RNA-Seq samples.')
}
```

### Load sample information

To make things easier, all of the relevant experiment sample information
including sample ID, condition, and batch have been stored in separate CSV
files.

During the processing of the analysis configuration above, the relevant
sample metadata was loaded. Here we create a few variables containing different
subsets of this information that will be useful throughout the downstream
analyses.

During the differential expression analysis, we will use a larger subset of the
samples in order to improve our estimation of variance and batch effects.

```{r prep_metadata}
# Sample metadata
sample_ids <- as.character(CONFIG$samples[[CONFIG$sample_id]])
condition  <- factor(CONFIG$samples[[CONFIG$condition]])
batch      <- factor(CONFIG$samples[[CONFIG$batch]])

# Covariate dataframe
covariates <- CONFIG$samples %>% select_(.dots=CONFIG$covariates)

# Make sure levels for batch and condition are valid
#levels(condition) <- make.names(levels(condition))
#levels(batch) <- make.names(levels(batch))

# Design matrix; this may be updated later if batch adjustment is enabled
design_condition_only  <- model.matrix(~0+condition)

if (length(levels(batch)) > 0) {
    design_including_batch <- model.matrix(~0+condition+batch)
}
```

### Load count tables

Next, we will use HPGLTools `r citep(citation('hpgltools'))` to load in the count
data for each sample. Throughout our analyses we will apply several different
types of filters and data transformations.  Since the exact types of
normalization and filtering procedures we will want to apply may differ,
depending on the type of analysis we are interested in (e.g.  differential
expression vs. co-expression network analysis), for each type of analysis, we
will maintain a list with the count tables at each of the major steps in
processing. Whenever genes or samples are removed from one version of the count
table for that analysis, the same genes and samples will be removed from all
other versions of the count table. This way we can ensure that the dimensions
of the count matrix is consistent across all levels of processing, within a
given analysis.

The different stages of processing which will be maintained are:

- **raw**: Unmodified count values as generated by HT-Seq, or another
   quantification tool.
- **log2cpm**: Log2 and counts-per-million (CPM) transformed.
- **normed**: Counts with zero or more of the follow transformations: log2,
  CPM, Voom, quantile normalization
- **batch_adjusted**: Same as above, but with an (optional) batch adjustment
  step. If "batch_adjust" is set to "none", this will be the same as the
  `normed` version of the counts.
- **final**: The final version of the counts after all filtering and
  transformation steps have been applied.

Finally, note that while all of the lists of count tables will include the same
raw and log2cpm transformed count matrices, everything for "normed" onwards
will depend on the exact parameters of the analysis, as specified in the
settings.

```{r prepare_count_matrix, message=FALSE, cache=CONFIG$use_cache, cache.lazy=FALSE, autodep=TRUE}
message("Preparing count matrix")

# Load from RData
if (file_ext(CONFIG$input_count_tables) == 'RData') {
    load(CONFIG$input_count_tables)
    count_table <- exprs(get(CONFIG$input_count_var))
    attributes(count_table)$names <- NULL
} else  {
    # Find all matching count files
    count_files <- Sys.glob(CONFIG$input_count_tables)

    # Single combined count file
    if (length(count_files) == 1) {
        # Load combined count table
        # TODO: Generalize so that counts stored in arbitrary formats can be loaded
        count_table <- read.table(CONFIG$input_count_tables, header=TRUE,
                                  row.names=1, check.names=FALSE) 
    } else {
        # Load from sample-specific count tables
        # ids <- regmatches(count_files, regexpr('(HPGL)?[0-9]{4,}', count_files))
        ids <- file_path_sans_ext(basename(count_files))
        count_table <- expt_read_counts(ids, count_files)
    }

    # Make sure HTSeq meta-columns are removed (should be taken care of in
    # recent versions of HPGLtools)
    count_table <- count_table[!grepl('^X__', rownames(count_table)),]
}

# Exclude any missing samples
#sample_ids <- sample_ids[sample_ids %in% colnames(count_table)]

# Filter out samples not needed for this analysis
count_table <- count_table[,sample_ids]

# Drop any rows with NA's (should only occur when comparing counts across
# experiments where different reference GFF's were used)
count_table <- count_table[complete.cases(count_table),]

# print initial size of raw count table
if (CONFIG$verbose) {
    print("Count table size:")
    dim(count_table)
}
```

```{r include=CONFIG$debug, eval=CONFIG$debug}
sum(count_table)
```

Sample Overview
---------------

### Library sizes

```{r libsizes, include=CONFIG$include_plots, eval=CONFIG$include_plots}
plot_libsize(count_table, condition, scale=FALSE)
```

### Outlier check

Sample median pairwise Pearson correlation for raw counts.

```{r outlier_check, include=CONFIG$include_plots, eval=CONFIG$include_plots}
plot_sample_correlations(count_table, condition, batch, mar=c(16,6,4,6))
```

